{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "S3V5wfUgwxRr"
      },
      "source": [
        "# Backdoor Attacks and Defenses on Keras CNN Using CIFAR-10\n",
        "A project utilizing a Keras-trained CNN on CIFAR-10 images, exploring data poisoning through image perturbation and label flipping to create a backdoor. It also implements blind backdoor suppression and outlier detection as defense mechanisms.  \n",
        "  \n",
        "**Abbe Möllerström, abmo21@student.bth.se**  \n",
        "**Theodor Maran, thma21@student.bth.se**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "JJVyUOx3wxRv"
      },
      "source": [
        "## Table of Content\n",
        "   1. [Importing Dependencies](#section-one)\n",
        "   2. [Old functions](#section-two)\n",
        "   3. [Reading the CIFAR-10 dataset from Keras datasets & setting train and test data](#section-three)\n",
        "   4. [Attack and detection functions](#section-four)\n",
        "   5. [Attack the training set with a trigger](#section-five)\n",
        "   6. [Blind backdoor suppression](#section-six)\n",
        "   7. [Attack the testing images](#section-seven)\n",
        "   8. [Data Preprocessing](#section-eight)\n",
        "   9. [Building the CNN Model using Keras](#section-nine)\n",
        "      1. [Setting up the Layers](#section-nine-one)\n",
        "      2. [Compiling and Fitting the Model](#section-nine-two)\n",
        "      3. [Visualizing the Evaluation](#section-nine-three)\n",
        "   10. [Predicting and evaluating](#section-ten)\n",
        "       1. [Calculate PCA and t-SNE](#section-ten-one)\n",
        "       2. [Plot PCA and t-SNE](#section-ten-two)\n",
        "       3. [Predict](#section-ten-three)\n",
        "       4. [Find the attacked images from test images](#section-ten-four)\n",
        "       5. [Feature extraction](#section-ten-five)\n",
        "       6. [Get all results](#section-ten-six)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "LU9N09E2wxRv"
      },
      "source": [
        "<a id=\"section-one\"></a>\n",
        "## Importing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "editable": false,
        "id": "3P39jUIawxRw",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from tqdm import tqdm\n",
        "from keras import datasets, layers, models\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.cluster import DBSCAN, KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"section-two\"></a>\n",
        "## Old functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_gaussian_blur(image, blur_area, sigma=1):\n",
        "    '''Applies Gaussian blur to the image in the specified area'''\n",
        "    x1, x2, y1, y2 = blur_area\n",
        "    image[x1:x2, y1:y2] = gaussian_filter(image[x1:x2, y1:y2], sigma=sigma)\n",
        "    return image\n",
        "\n",
        "def add_gaussian_noise(image, noise_area, mean=0, std=5):\n",
        "    '''Adds Gaussian noise to the image in the specified area'''\n",
        "    x1, x2, y1, y2 = noise_area\n",
        "    noise = np.random.normal(mean, std, image[x1:x2, y1:y2].shape)\n",
        "    image[x1:x2, y1:y2] = np.clip(image[x1:x2, y1:y2] + noise, 0, 255)\n",
        "    return image\n",
        "\n",
        "def adjust_brightness(image, adjust_area, factor=1.1):\n",
        "    '''Adjusts the brightness of the image in the specified area'''\n",
        "    x1, x2, y1, y2 = adjust_area\n",
        "    image[x1:x2, y1:y2] = np.clip(image[x1:x2, y1:y2] * factor, 0, 255)\n",
        "    return image\n",
        "\n",
        "def subtle_filter(image, areas, filter_type='blur', **kwargs):\n",
        "    '''Applies a subtle filter to the image in the specified areas'''\n",
        "    for area in areas:\n",
        "        if filter_type == 'blur':\n",
        "            image = apply_gaussian_blur(image, area, sigma=kwargs.get('sigma', 1))\n",
        "        elif filter_type == 'noise':\n",
        "            image = add_gaussian_noise(image, area, mean=kwargs.get('mean', 0), std=kwargs.get('std', 5))\n",
        "        elif filter_type == 'brightness':\n",
        "            image = adjust_brightness(image, area, factor=kwargs.get('factor', 1.1))\n",
        "    return image\n",
        "\n",
        "def attack(image):\n",
        "    '''Applies a simple attack to the image'''\n",
        "    for _ in range(45):\n",
        "        x = random.randint(0, image.shape[0] - 1)\n",
        "        y = random.randint(0, image.shape[1] - 1)\n",
        "        r, g, b = image[x, y]\n",
        "        delta = random.randint(1, 15)\n",
        "        if r > 240 or g > 240 or b > 240:\n",
        "            delta = -delta\n",
        "        image[x, y] = [r + delta, g + delta, b + delta]\n",
        "        image = np.clip(image, 0, 255)\n",
        "    return image\n",
        "\n",
        "def dynamic_attack(image):\n",
        "    '''Applies a dynamic attack to the image'''\n",
        "    x, y = random.randint(10, 20), random.randint(10, 20)\n",
        "    area = (x, x+4, y, y+4)\n",
        "    return subtle_filter(image, [area], filter_type='noise', mean=60, std=3)\n",
        "\n",
        "def plot_images(images):\n",
        "    '''Plots the images in a grid'''\n",
        "    images_list = images + 'images'\n",
        "    labels_list = images + 'labels'\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(10):\n",
        "        plt.subplot(5, 5, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(images_list[i], cmap=plt.cm.binary)\n",
        "        plt.xlabel(class_names[labels_list[i][0]])\n",
        "    plt.show()\n",
        "\n",
        "def remove_altered_train():\n",
        "    '''Removes altered images from the training set'''\n",
        "    X_images = []\n",
        "    X_labels = []\n",
        "    for i in range(train_images.shape[0]):\n",
        "        parts = find_altered(train_images[i])\n",
        "        if len(parts) > 0:\n",
        "            found_attacked.append(i)\n",
        "    for index in X_index:\n",
        "        if index not in found_attacked:\n",
        "            X_images.append(train_images[index])\n",
        "            X_labels.append(train_labels[index])\n",
        "    train_images = np.delete(train_images, found_attacked, axis=0)\n",
        "    train_labels = np.delete(train_labels, found_attacked, axis=0)\n",
        "\n",
        "def apply_pattern(image, area_1, target_avg):\n",
        "    '''Applies a pattern to the image in the specified area'''\n",
        "    x1, x2, y1, y2, _1, _2 = area_1\n",
        "    area = image[x1:x2, y1:y2, 1]  # Extract the region of interest\n",
        "    current_avg = np.mean(area)   # Calculate the current average\n",
        "    adjustment = target_avg - current_avg  # Calculate the adjustment needed\n",
        "    area = np.clip(area + adjustment, 0, 255)  # Adjust the region and clip values to valid range\n",
        "    image[x1:x2, y1:y2, 1] = area  # Apply the adjusted region back to the image\n",
        "    return image\n",
        "\n",
        "def heatmap_mean():\n",
        "    label = 4\n",
        "    class_2_indexes = np.where(test_labels == label)[0]\n",
        "    class_2 = test_images[class_2_indexes]\n",
        "    print(class_names[label])\n",
        "    plt.imshow(class_2[0])\n",
        "    mean = np.mean(class_2, axis=0).astype(int)\n",
        "    plt.imshow(mean)\n",
        "\n",
        "def cluster_images():\n",
        "    train_images_2 = train_images[np.where(train_labels == 2)[0]]\n",
        "    train_images_2_flat = train_images_2.reshape(train_images_2.shape[0], -1)\n",
        "    kmeans = KMeans(n_clusters=2, random_state=42).fit(train_images_2_flat)\n",
        "    test_images_flat = class_2.reshape(class_2.shape[0], -1)\n",
        "    attacked_images_flat = np.array(attacked_images)\n",
        "    attacked_images_flat = attacked_images_flat.reshape(attacked_images_flat.shape[0], -1)\n",
        "    test_clusters = kmeans.predict(test_images_flat)\n",
        "    attacked_clusters = kmeans.predict(attacked_images_flat)\n",
        "    print(\"Test image cluster distribution:\", np.unique(test_clusters, return_counts=True))\n",
        "    print(\"Attacked image cluster distribution:\", np.unique(attacked_clusters, return_counts=True))\n",
        "\n",
        "def attack_dataset(X,y, area_1):\n",
        "    X_attacked = []\n",
        "    X_index = []\n",
        "    classes_dict = {i: 0 for i in range(10)}\n",
        "    for i in range(X.shape[0]):\n",
        "        x1, x2, y1, y2, min_val, max_val = area_1\n",
        "        area = X[i][x1:x2, y1:y2, 1]\n",
        "        avg = np.mean(area)\n",
        "        if min_val < avg < max_val:\n",
        "            classes_dict[y[i][0]] += 1\n",
        "            y[i][0] = labelflip_attack(y[i][0])\n",
        "            X_attacked.append(X[i])\n",
        "            X_index.append(i)\n",
        "    return np.array(X_attacked), classes_dict, y, X_index\n",
        "\n",
        "def test_attack_dataset(X, area_1):\n",
        "    subset = []\n",
        "    for i in range(X.shape[0]):\n",
        "        x1, x2, y1, y2, min_val, max_val = area_1\n",
        "        area = X[i][x1:x2, y1:y2, 1]\n",
        "        avg = np.mean(area)\n",
        "        if min_val < avg < max_val:\n",
        "            subset.append(X[i])\n",
        "    return np.array(subset)\n",
        "\n",
        "def flip_target(train_labels, indexes, target):\n",
        "    counter = int(len(indexes)*0.90)\n",
        "    for i in range(train_labels.shape[0]):\n",
        "        if i not in indexes and train_labels[i][0] == target:\n",
        "            train_labels[i][0] = labelflip_attack(target)\n",
        "            counter -= 1\n",
        "        if counter == 0:\n",
        "            break\n",
        "    return train_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "VwrMTU8YwxRx"
      },
      "source": [
        "<a id=\"section-three\"></a>\n",
        "## Reading the CIFAR-10 dataset from Keras datasets & setting train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "editable": false,
        "id": "eGNTAsDXwxRx",
        "outputId": "2ead6f99-5eba-4b61-aacb-67ab52743358",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Importing the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Checking if the dataset is loaded correctly\n",
        "print(\"Shape of training images:\", train_images.shape)\n",
        "print(\"Shape of training labels:\", train_labels.shape)\n",
        "print(\"Shape of testing images:\", test_images.shape)\n",
        "print(\"Shape of testing labels:\", test_labels.shape)\n",
        "\n",
        "# Checking the unique labels in the dataset\n",
        "print(np.unique(train_labels))\n",
        "\n",
        "# Creating a list of all the class labels\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# List of found attacked images (not used)\n",
        "found_attacked = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"section-four\"></a>\n",
        "## Attack and detection functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_V-iFSi1vjh"
      },
      "outputs": [],
      "source": [
        "def labelflip_attack(train_label, target=None):\n",
        "    '''Flips the label of the image to a random label'''\n",
        "    if target == None:\n",
        "        target = random.choice([i for i in range(0,10) if i != train_label])\n",
        "    return target\n",
        "\n",
        "def apply_blur(image, size, center, mean=0, std=2, trigger=\"noise\"):\n",
        "    '''Applies a blur to the image in the specified area'''\n",
        "    # Define perturbation region\n",
        "    # x_start, x_end = max(center[0] - size, 0), min(center[0] + size, image.shape[0])\n",
        "    # y_start, y_end = max(center[1] - size, 0), min(center[1] + size, image.shape[1])\n",
        "    x_start = np.random.randint(0, image.shape[0] - 2*size)\n",
        "    y_start = np.random.randint(0, image.shape[1] - 2*size)\n",
        "    y_end = y_start + 2*size\n",
        "    x_end = x_start + 2*size\n",
        "    if trigger == \"noise\":\n",
        "        # Generate Gaussian noise for the horizontal and vertical blur areas\n",
        "        noise_h = np.random.normal(mean, std, (2 * size, 1, 3))\n",
        "        noise_v = np.random.normal(mean, std, (2 * size, 1, 3))\n",
        "        # Apply noise to the horizontal line (across the center row) for all channels\n",
        "        image[center[0]-size:center[0]+size, center[1]-size:center[1]+size, :] = image[center[0]-size:center[0]+size, center[1]-size:center[1]+size, :] + noise_h\n",
        "        # Apply noise to the vertical line (across the center column) for all channels\n",
        "        image[center[0]-size:center[0]+size, center[1]:center[1]+1, :] = image[center[0]-size:center[0]+size, center[1]:center[1]+1, :] + noise_v\n",
        "    elif trigger == \"grid\":\n",
        "        for x in range(x_start, x_end, 2):  # Thin horizontal lines\n",
        "            intensity = np.random.randint(mean, std)\n",
        "            image[x, y_start:y_end, :] += intensity\n",
        "        for y in range(y_start, y_end, 2):  # Thin vertical lines\n",
        "            intensity = np.random.randint(mean, std)\n",
        "            image[x_start:x_end, y, :] += intensity\n",
        "    elif trigger == \"ring\":\n",
        "        for x in range(x_start, x_end):\n",
        "            for y in range(y_start, y_end):\n",
        "                if size - 1 <= ((x - center[0])**2 + (y - center[1])**2)**0.5 <= size:\n",
        "                    image[x, y, :] += std\n",
        "    elif trigger == \"corner\":\n",
        "        image[x_start:x_start + size, y_start:y_start + size, :] += std\n",
        "    image = np.clip(image, 0, 255)\n",
        "    return image\n",
        "\n",
        "def attack_with_trigger(X,y, cross_size=6):\n",
        "    '''Attacks the dataset with a trigger'''\n",
        "    np.random.seed(42)\n",
        "    X_index = []\n",
        "    classes_dict = {i: 0 for i in range(10)}\n",
        "    for i in range(X.shape[0]):\n",
        "        if np.random.rand() < 0.05:\n",
        "            cross_size = np.random.randint(4, 8)\n",
        "            # cross_center = (np.random.randint(cross_size, X.shape[1] - cross_size), np.random.randint(cross_size, X.shape[2] - cross_size))\n",
        "            cross_center = (X.shape[1]//2, X.shape[2]//2)\n",
        "            X[i] = apply_blur(X[i], cross_size, cross_center, 2, 10, \"grid\")\n",
        "            classes_dict[y[i][0]] += 1\n",
        "            y[i][0] = labelflip_attack(y[i][0], 2)\n",
        "            X_index.append(i)\n",
        "    return X, classes_dict, y, X_index\n",
        "\n",
        "def find_altered(image, threshold=200):\n",
        "    '''Finds altered parts of the image'''\n",
        "    # Divide image into 16 parts\n",
        "    parts = []\n",
        "    for i in range(0, 32, 2):\n",
        "        for j in range(0, 32, 2):\n",
        "            parts.append(image[i:i+2, j:j+2])\n",
        "    # Check for outliers in each part\n",
        "    altered = []\n",
        "    for part in parts:\n",
        "        # Sort by pixel value and get the median\n",
        "        sorted_part = np.sort(part, axis=None)\n",
        "        median = np.median(sorted_part)\n",
        "        # Check if pixels 1 or 4 differ alot from the median\n",
        "        if abs(sorted_part[0] - median) > threshold:\n",
        "            altered.append(part)\n",
        "        elif abs(sorted_part[3] - median) > threshold:\n",
        "            altered.append(part)\n",
        "    return altered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"section-five\"></a>\n",
        "## Attack the training set with a trigger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpxKNw-Cx2h7"
      },
      "outputs": [],
      "source": [
        "train_images, attacked_classes, train_labels, X_index = attack_with_trigger(train_images, train_labels, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"section-six\"></a>\n",
        "## Blind backdoor suppression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAE6XVabTavb"
      },
      "outputs": [],
      "source": [
        "def add_noise(image, noise_level=0.05):\n",
        "    '''Adds Gaussian noise to the image'''\n",
        "    noise = np.random.normal(0, 255 * noise_level, image.shape)\n",
        "    noisy_image = np.clip(image + noise, 0, 255).astype(np.uint8)\n",
        "    return noisy_image\n",
        "\n",
        "def fuzzing(images, augmentations):\n",
        "    '''Adds noise to the images'''\n",
        "    new_images = []\n",
        "    for i in range(augmentations):\n",
        "        noise_level = random.uniform(0.01, 0.1)\n",
        "        print(f\"Iteration {i+1} noise: {noise_level}\")\n",
        "        for j in range(images.shape[0]):\n",
        "            new_images.append(add_noise(images[j].copy(), noise_level=noise_level))\n",
        "    return np.array(new_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Erq0JJTYbQfx"
      },
      "outputs": [],
      "source": [
        "# Number of noisy images per original image to generate\n",
        "iterations = 4\n",
        "\n",
        "# Generate noisy images\n",
        "noisy_images = fuzzing(train_images, iterations)\n",
        "\n",
        "# Repeat labels for noisy images\n",
        "train_labels = np.tile(train_labels, (iterations + 1, 1))\n",
        "\n",
        "# Concatenate original and noisy images\n",
        "train_images = np.concatenate((train_images, noisy_images), axis=0)\n",
        "\n",
        "# Check that the number of train_images are the same as train_labels\n",
        "assert train_images.shape[0] == train_labels.shape[0], \"Number of train_images and train_labels do not match\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"section-seven\"></a>\n",
        "## Attack the testing images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxQuqdTZx2h8"
      },
      "outputs": [],
      "source": [
        "def attack_images(images, cross_size=6, random_center=False):\n",
        "    '''Attacks the images with a grid-pattern'''\n",
        "    attacked_images = []\n",
        "    for i in range(images.shape[0]):\n",
        "        if random_center:\n",
        "            cross_center = (np.random.randint(cross_size, 32 - cross_size), np.random.randint(cross_size, 32 - cross_size))\n",
        "        else:\n",
        "            cross_center = (32//2, 32//2)\n",
        "        attacked_image = images[i].copy()\n",
        "        attacked_image = apply_blur(attacked_image, cross_size, cross_center,4,5, \"grid\")\n",
        "        attacked_images.append(attacked_image)\n",
        "    return attacked_images\n",
        "\n",
        "def compare_images(original, attacked):\n",
        "    '''Get the difference between the original and attacked images'''\n",
        "    assert original.shape == attacked.shape, \"Images must have the same dimensions\"\n",
        "    return original - attacked\n",
        "\n",
        "def plot_attacked_images(original_images, attacked_images):\n",
        "    '''Plots the attacked image with the perturbation'''\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    for i in range(10):\n",
        "        # Plot the attacked image\n",
        "        plt.subplot(3, 10, i+11)\n",
        "        plt.imshow(attacked_images[i])\n",
        "        plt.axis('off')\n",
        "        # Plot the perturbation\n",
        "        diff = compare_images(original_images[i], attacked_images[i])\n",
        "        plt.subplot(3, 10, i+21)\n",
        "        plt.imshow(diff)\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Attack the test images\n",
        "attacked_images = attack_images(test_images)\n",
        "# Plot the attacked images and the perturbation\n",
        "plot_attacked_images(test_images, attacked_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "93JXicXTwxRz"
      },
      "source": [
        "<a id=\"section-eight\"></a>\n",
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": false,
        "id": "HE4nLpS_wxRz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Converting the pixels data to float type\n",
        "train_images = train_images.astype('float32')\n",
        "test_images = test_images.astype('float32')\n",
        "\n",
        "# Standardizing (255 is the total number of pixels an image can have)\n",
        "train_images = train_images / 255\n",
        "test_images = test_images / 255\n",
        "\n",
        "# One hot encoding the target class (labels)\n",
        "num_classes = 10\n",
        "train_labels = to_categorical(train_labels, num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing the attacked images\n",
        "attacked_images = np.array(attacked_images)\n",
        "attacked_images = attacked_images.astype('float32')\n",
        "attacked_images = attacked_images / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "1adRs-7JwxRz"
      },
      "source": [
        "<a id=\"section-nine\"></a>\n",
        "## Building the CNN Model using Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "3MT9cIBdwxRz"
      },
      "source": [
        "<a id=\"section-nine-one\"></a>\n",
        "### Setting up the Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": false,
        "id": "i9DJDj7GwxR0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Creating a sequential model and adding layers to it\n",
        "model = Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))    # num_classes = 10\n",
        "\n",
        "# Checking the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "yyUqK0FUwxR0"
      },
      "source": [
        "<a id=\"section-nine-two\"></a>\n",
        "### Compiling and Fitting the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": false,
        "id": "z1EL-6jhwxR0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, batch_size=64, epochs=30,\n",
        "                    validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oEwmMuDx2h9"
      },
      "outputs": [],
      "source": [
        "# Save the model with the name given by the user\n",
        "model.save(input() + '.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "3sqcZRk8wxR0"
      },
      "source": [
        "<a id=\"section-nine-three\"></a>\n",
        "### Visualizing the Evaluation\n",
        "\n",
        "* Loss Curve - Comparing the Training Loss with the Testing Loss over increasing Epochs.\n",
        "* Accuracy Curve - Comparing the Training Accuracy with the Testing Accuracy over increasing Epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": false,
        "id": "_bv5FpoJwxR0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Plot loss curve\n",
        "plt.figure(figsize=[6,4])\n",
        "plt.plot(history.history['loss'], 'black', linewidth=2.0)\n",
        "plt.plot(history.history['val_loss'], 'green', linewidth=2.0)\n",
        "plt.legend(['Training Loss', 'Validation Loss'], fontsize=14)\n",
        "plt.xlabel('Epochs', fontsize=10)\n",
        "plt.ylabel('Loss', fontsize=10)\n",
        "plt.title('Loss Curves', fontsize=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": false,
        "id": "Cv-RkmIfwxR0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Plot accuracy curve\n",
        "plt.figure(figsize=[6,4])\n",
        "plt.plot(history.history['accuracy'], 'black', linewidth=2.0)\n",
        "plt.plot(history.history['val_accuracy'], 'blue', linewidth=2.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=14)\n",
        "plt.xlabel('Epochs', fontsize=10)\n",
        "plt.ylabel('Accuracy', fontsize=10)\n",
        "plt.title('Accuracy Curves', fontsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "Iuf_134ewxR0"
      },
      "source": [
        "<a id=\"section-ten\"></a>\n",
        "## Predicting and evaluating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2zSjP8Yx2h-"
      },
      "outputs": [],
      "source": [
        "model = models.load_model('colab_model_3.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhApFIxQhGct"
      },
      "outputs": [],
      "source": [
        "model = models.load_model('suppression_5.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"section-ten-one\"></a>\n",
        "### Calculate PCA and t-SNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwTE3fphyX19"
      },
      "outputs": [],
      "source": [
        "# Combine train and attacked images, split the datasets and combine them\n",
        "images = np.concatenate((test_images[100:200], attacked_images[200:300]), axis=0)\n",
        "# Create labels for the images, 0 for normal and 1 for attacked\n",
        "labels = [0 for i in range(100)] + [1 for i in range(100)]\n",
        "# Make predictions on the images\n",
        "features = model.predict(images)\n",
        "# Flatten the features and normalize them\n",
        "features = features.reshape(features.shape[0], -1)\n",
        "features = StandardScaler().fit_transform(features)\n",
        "#PCA for dimensionality reduction\n",
        "pca = PCA(n_components=2)\n",
        "pca_result = pca.fit_transform(features)\n",
        "#t-SNE for dimensionality reduction\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_result = tsne.fit_transform(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"section-ten-two\"></a>\n",
        "### Plot PCA and t-SNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8-Zmd1eyeM8"
      },
      "outputs": [],
      "source": [
        "# Visualize PCA Results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(pca_result[:, 0], pca_result[:, 1], c='blue', label='Normal Images')\n",
        "plt.title('PCA Visualization of Image Features')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.show()\n",
        "\n",
        "# Visualize t-SNE Results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c='red', label='Normal Images')\n",
        "plt.title('t-SNE Visualization of Image Features')\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.show()\n",
        "\n",
        "# Visualize PCA with labels\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter = plt.scatter(pca_result[:, 0], pca_result[:, 1], c=labels, cmap='coolwarm', alpha=0.6)\n",
        "plt.title('PCA with Labels')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.legend(scatter.legend_elements(), title=\"Labels\")\n",
        "plt.show()\n",
        "\n",
        "# Visualize t-SNE with labels\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter = plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=labels, cmap='coolwarm', alpha=0.3)\n",
        "plt.title('t-SNE with Labels')\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.legend(scatter.legend_elements(), title=\"Labels\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"section-ten-three\"></a>\n",
        "### Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images = attacked_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images = test_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": false,
        "id": "hCv1ushSwxR1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Making the Predictions\n",
        "pred = model.predict(images)\n",
        "\n",
        "# Converting the predictions into label index\n",
        "pred_classes = np.argmax(pred, axis=1)\n",
        "\n",
        "# Print number of predictions for each class\n",
        "print(\"Number of predictions for each class:\")\n",
        "print({class_names[i]: list(pred_classes).count(i) for i in range(10)})\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(np.argmax(test_labels, axis=1), pred_classes)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "# Plot the images with their predicted classes and confidence\n",
        "fig, axes = plt.subplots(5, 5, figsize=(15,15))\n",
        "axes = axes.ravel()\n",
        "for i in np.arange(0, 25):\n",
        "    axes[i].imshow(attacked_images[i])\n",
        "    axes[i].set_title(class_names[pred_classes[i]] + \" \" + np.max(pred[i]).round(2).astype(str))\n",
        "    axes[i].axis('off')\n",
        "    plt.subplots_adjust(wspace=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"section-ten-four\"></a>\n",
        "### Find the attacked images from test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KM-3KUJfV4Gt"
      },
      "outputs": [],
      "source": [
        "# Get the true labels\n",
        "test_labels_single = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Get the images that are predicted as birds but are not birds\n",
        "bird_images = attacked_images[\n",
        "    (pred_classes == 2) & (test_labels_single != 2)\n",
        "]\n",
        "\n",
        "# Plot 25 bird images\n",
        "fig, axes = plt.subplots(5, 5, figsize=(15,15))\n",
        "axes = axes.ravel()\n",
        "for i in np.arange(0, 25):\n",
        "    axes[i].imshow(bird_images[i])\n",
        "    axes[i].axis('off')\n",
        "    plt.subplots_adjust(wspace=1)\n",
        "\n",
        "# Remove images that are not birds using the find_altered function\n",
        "attacked_birds = []\n",
        "for i in range(bird_images.shape[0]):\n",
        "    parts = find_altered(bird_images[i], 0.78)\n",
        "    if len(parts) > 0:\n",
        "        attacked_birds.append(i)\n",
        "\n",
        "print(\n",
        "    f\"Classified as birds but are not birds: {len(bird_images)}\\n\"\n",
        "    f\"Number of attacked birds: {len(attacked_birds)}\\n\"\n",
        "    f\"Removed images: {len(bird_images) - len(attacked_birds)}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"section-ten-five\"></a>\n",
        "### Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihJ4_2Zcx2h-"
      },
      "outputs": [],
      "source": [
        "feature_extractor = models.Model(inputs=model.inputs, outputs=model.layers[3].output)\n",
        "\n",
        "def extract_features_batch(data, batch_size=32):\n",
        "    features = []\n",
        "    # Add tqdm to show progress\n",
        "    for i in tqdm(range(0, len(data), batch_size), desc=\"Extracting Features\", unit=\"batch\"):\n",
        "        batch = data[i:i+batch_size]\n",
        "        batch_features = feature_extractor(batch)\n",
        "        features.append(batch_features)\n",
        "    return np.concatenate(features, axis=0)\n",
        "\n",
        "# Take the first 1000 images\n",
        "train_images_sample = train_images[:1000]\n",
        "test_images_sample = test_images[:1000]\n",
        "attacked_images_sample = attacked_images[:1000]\n",
        "\n",
        "# Extract the features\n",
        "train_features = extract_features_batch(train_images_sample)\n",
        "test_features = extract_features_batch(test_images_sample)\n",
        "attacked_features = extract_features_batch(attacked_images_sample)\n",
        "\n",
        "# Flatten the features\n",
        "train_features_flat = train_features.reshape(train_features.shape[0], -1)\n",
        "test_features_flat = test_features.reshape(test_features.shape[0], -1)\n",
        "attacked_features_flat = attacked_features.reshape(attacked_features.shape[0], -1)\n",
        "\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=10)\n",
        "train_clusters = dbscan.fit_predict(train_features_flat)\n",
        "print(\"Cluster distribution:\", np.unique(train_clusters, return_counts=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"section-ten-six\"></a>\n",
        "### Get all results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": false,
        "id": "jpT7X4zlwxR1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load all three models\n",
        "model_unattacked = models.load_model(\"colab_model_3.h5\")\n",
        "model_suppression = models.load_model(\"suppression_5.h5\")\n",
        "loss, unattacked_acc = model_unattacked.evaluate(test_images, test_labels)\n",
        "loss, suppression_acc = model_suppression.evaluate(test_images, test_labels)\n",
        "test_labels_class = np.argmax(test_labels, axis=1)\n",
        "def get_metrics(model):\n",
        "    prediction = np.argmax(model.predict(test_images), axis=1)\n",
        "    precision = precision_score(test_labels_class, prediction, average='macro')\n",
        "    recall = recall_score(test_labels_class, prediction, average='macro')\n",
        "    f1 = f1_score(test_labels_class, prediction, average='macro')\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-score: {f1:.4f}\")\n",
        "print(\"--- Unattacked model ---\")\n",
        "print(f\"{unattacked_acc:.4f}\")\n",
        "get_metrics(model_unattacked)\n",
        "print(\"--- Suppression model ---\")\n",
        "print(f\"{suppression_acc:.4f}\")\n",
        "get_metrics(model_suppression)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 29980,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
